{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Access and Download of Raw NEE and Environmental Predictor Data\n",
        "\n",
        "Author: Aline Andrade do Nascimento\n",
        "\n",
        "Affiliation: PhD Candidate in Applied Computing, National Institute for Space Research (INPE)\n",
        "\n",
        "Contact: alinephysics@gmail.com | aline.andrade@inpe.br\n",
        "\n",
        "Date: July 2025\n",
        "\n",
        "This notebook provides code snippets and links to access and download raw environmental datasets commonly used as predictors in Net Ecosystem Exchange (NEE) modeling in the Amazon.\n",
        "It does not include any data preprocessing or analysis. The main goal is to centralize the procedures for retrieving datasets from multiple sources such as Google Earth Engine (GEE), ECMWF (ERA5), NASA (CERES), and others."
      ],
      "metadata": {
        "id": "S7Pyx1epCuqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ☀️ ERA5 Hourly Data on Single Levels (1940–present)\n",
        "\n",
        "**Dataset:** [ERA5 - Single Levels (Copernicus Climate Data Store)](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels?tab=overview)  \n",
        "**Provider:** ECMWF / Copernicus Climate Data Store (CDS)\n",
        "\n",
        "**Description:**  \n",
        "ERA5 provides hourly estimates of a wide range of climate variables at a single level (surface or near-surface), from 1940 to the present. This reanalysis product is generated by combining model data with observations using data assimilation techniques.\n",
        "\n",
        "**Common variables used as predictors for NEE modeling include:**\n",
        "- `2m_temperature`: Air temperature at 2 meters\n",
        "- `total_precipitation`: Precipitation (rain + snow)\n",
        "- `evaporation`: Total evaporation from surface\n",
        "- `volumetric_soil_water_layer_1`: Soil moisture in upper layer\n",
        "\n",
        "**Requirements:**\n",
        "- A CDS account (free registration) is required to use the API.\n",
        "- Data are downloaded using the CDS Python API (`cdsapi`).\n",
        "- Files are typically saved in NetCDF format."
      ],
      "metadata": {
        "id": "VS4XzAl7lA2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install 'cdsapi>=0.7.2'"
      ],
      "metadata": {
        "id": "D4cgF9fAGg71",
        "outputId": "0aaececd-31d8-4b45-8ecf-88343ed41b06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cdsapi>=0.7.2\n",
            "  Downloading cdsapi-0.7.6-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting ecmwf-datastores-client (from cdsapi>=0.7.2)\n",
            "  Downloading ecmwf_datastores_client-0.2.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from cdsapi>=0.7.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from cdsapi>=0.7.2) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.5.0->cdsapi>=0.7.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.5.0->cdsapi>=0.7.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.5.0->cdsapi>=0.7.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.5.0->cdsapi>=0.7.2) (2025.6.15)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from ecmwf-datastores-client->cdsapi>=0.7.2) (25.3.0)\n",
            "Collecting multiurl>=0.3.2 (from ecmwf-datastores-client->cdsapi>=0.7.2)\n",
            "  Downloading multiurl-0.3.5-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from ecmwf-datastores-client->cdsapi>=0.7.2) (4.14.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from multiurl>=0.3.2->ecmwf-datastores-client->cdsapi>=0.7.2) (2025.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from multiurl>=0.3.2->ecmwf-datastores-client->cdsapi>=0.7.2) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->multiurl>=0.3.2->ecmwf-datastores-client->cdsapi>=0.7.2) (1.17.0)\n",
            "Downloading cdsapi-0.7.6-py2.py3-none-any.whl (12 kB)\n",
            "Downloading ecmwf_datastores_client-0.2.0-py3-none-any.whl (28 kB)\n",
            "Downloading multiurl-0.3.5-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: multiurl, ecmwf-datastores-client, cdsapi\n",
            "Successfully installed cdsapi-0.7.6 ecmwf-datastores-client-0.2.0 multiurl-0.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j3Ef_wakGE7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247d1116-150d-417e-8737-cd8213109d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-07 23:21:06,711 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
            "INFO:ecmwf.datastores.legacy_client:[2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n"
          ]
        }
      ],
      "source": [
        "import cdsapi\n",
        "\n",
        "cdsapi_key = 'get your key in site'\n",
        "client = cdsapi.Client(url='https://cds.climate.copernicus.eu/api', key=cdsapi_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_years = ['2002','2003','2004','2005','2006','2007','2008','2009','2010','2011']\n",
        "list_months = ['01','02', '03',\n",
        "            '04', '05', '06',\n",
        "            '07', '08', '09',\n",
        "            '10', '11', '12']\n",
        "\n",
        "list_days = ['01', '02', '03',\n",
        "            '04', '05', '06',\n",
        "            '07', '08', '09',\n",
        "            '10', '11', '12',\n",
        "            '13', '14', '15',\n",
        "            '16', '17', '18',\n",
        "            '19', '20', '21',\n",
        "            '22', '23', '24',\n",
        "            '25', '26', '27',\n",
        "            '28', '29', '30']\n"
      ],
      "metadata": {
        "id": "sl6U4t4xH83W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "era5_atmosphere_initial = ['2m_dewpoint_temperature', '2m_temperature', 'evaporation',\n",
        "            'near_ir_albedo_for_diffuse_radiation', 'uv_visible_albedo_for_diffuse_radiation', 'precipitation_type',\n",
        "                           'runoff','soil_temperature_level_1', 'total_precipitation','total_column_water_vapour']\n"
      ],
      "metadata": {
        "id": "sXsFL5DDH4CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spatial Bounds – Brazilian Amazon Biome (ERA5 Regular Grid)\n",
        "north = 5.090000000000001\n",
        "west = -73.97999999999999\n",
        "south = -16.66\n",
        "east = -43.48\n",
        "\n",
        "# west, south, east, north = bounds\n",
        "print(f\"{north}/{west}/{south}/{east}\")"
      ],
      "metadata": {
        "id": "B7_YR7xOGL14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "\n",
        "def download_data(year,variable):\n",
        "\n",
        "    # Update the path to your local directory\n",
        "    filename = '/content/drive/MyDrive/bioma_amazonia_era5_single_one/era5_hourly_netcdf_grid_bioma_amazonia/grid-era5-hourly-data-single-level-' + year +  '-' + variable + '.nc'\n",
        "\n",
        "    c.retrieve(\n",
        "        'reanalysis-era5-single-levels',\n",
        "        {\n",
        "            'product_type': 'reanalysis',\n",
        "            'variable': [variable],\n",
        "            'year': year,\n",
        "            'month': list_months,\n",
        "            'day': list_days,\n",
        "            'time': [\n",
        "                '00:00', '01:00', '02:00',\n",
        "                '03:00', '04:00', '05:00',\n",
        "                '06:00', '07:00', '08:00',\n",
        "                '09:00', '10:00', '11:00',\n",
        "                '12:00', '13:00', '14:00',\n",
        "                '15:00', '16:00', '17:00',\n",
        "                '18:00', '19:00', '20:00',\n",
        "                '21:00', '22:00', '23:00',\n",
        "            ],\n",
        "            'format': 'netcdf',\n",
        "            \"area\": f\"{north}/{west}/{south}/{east}\"\n",
        "        },\n",
        "        filename)\n",
        "\n",
        "    print(filename, 'saved!')\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    futures = []\n",
        "    for variable in era5_atmosphere_initial:\n",
        "      futures.append(executor.submit(download_data, '2006', variable))\n",
        "\n",
        "    # Await completion of all tasks\n",
        "    concurrent.futures.wait(futures)"
      ],
      "metadata": {
        "id": "dQRbIa-nG7RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🌿 MODIS Products\n",
        "\n",
        "**Description:**  \n",
        "The Moderate Resolution Imaging Spectroradiometer (MODIS) provides a wide range of remote sensing data products relevant for ecosystem and climate studies. MODIS data include vegetation indices, land surface temperature, and reflectance, among others, which are commonly used as predictors in NEE modeling.\n",
        "\n",
        "**Access:**  \n",
        "MODIS data can be accessed through Google Earth Engine (GEE), NASA’s LP DAAC, or other data portals.\n",
        "\n"
      ],
      "metadata": {
        "id": "ikn1GBwLkyYm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drEALl8zR-Sh"
      },
      "source": [
        "## Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wLi_zGh6sXr",
        "outputId": "4f3aedcc-b5f8-4586-ef9b-3c447c26461e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.2\n",
            "time: 257 µs (started: 2025-07-07 23:24:46 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S5tqWPV7np_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320bb674-b19c-47f4-cdae-c6472b20fb05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "time: 43.8 s (started: 2025-07-07 23:24:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cZD2H-Kin-4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e132e3-122b-4ef2-cc39-1061d82202ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting fiona\n",
            "  Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (2.1.1)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.11/dist-packages (3.7.1)\n",
            "Collecting rtree\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from fiona) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from fiona) (2025.6.15)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.11/dist-packages (from fiona) (8.2.1)\n",
            "Collecting click-plugins>=1.0 (from fiona)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting cligj>=0.5 (from fiona)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: rtree, cligj, click-plugins, affine, rasterio, fiona\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 fiona-1.10.1 rasterio-1.4.3 rtree-1.4.0\n",
            "time: 10.5 s (started: 2025-07-07 23:25:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas fiona shapely pyproj rtree rasterio geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axfcz745C4uL"
      },
      "outputs": [],
      "source": [
        "pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eflZnk8_n-zc"
      },
      "outputs": [],
      "source": [
        "pip install geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qyZk04Zcn-pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8127139-6fce-4de6-9eeb-a8aae67d0af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.68 s (started: 2025-07-07 23:25:42 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Libraries to open 'netcdf' file\n",
        "# import netCDF4 as netcdf\n",
        "import xarray\n",
        "\n",
        "# To pre-process dataframe and use in visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import rasterio as rio\n",
        "import shapely\n",
        "from shapely.geometry import Point\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_list_csv_files(path):\n",
        "  directory = path\n",
        "  files = []\n",
        "  for filename in os.listdir(directory):\n",
        "    f = os.path.join(directory, filename)\n",
        "\n",
        "    if (os.path.isfile(f)) and ('.csv' in f):\n",
        "      files.append(f)\n",
        "  return files"
      ],
      "metadata": {
        "id": "gwpMPW0-TRTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48beb61-f79a-4594-aecf-044e2f0d7472"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.08 ms (started: 2025-07-07 23:25:53 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M7eqvrn3vNYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b94f10-0af7-41cb-8b10-6350c9628520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 951 µs (started: 2025-07-07 23:25:54 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def get_list_shp_files(path):\n",
        "  directory = path\n",
        "  files = []\n",
        "  for filename in os.listdir(directory):\n",
        "    f = os.path.join(directory, filename)\n",
        "\n",
        "    if (os.path.isfile(f)) and ('.shp' in f):\n",
        "      files.append(f)\n",
        "  return files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C35CSoue21tr"
      },
      "source": [
        "##  Connecting Google Earth Engine (GEE) with Other Google Services\n",
        "\n",
        "A API do Python do Earth Engine e as ferramentas de linha de comando podem ser instaladas usando a ferramenta de instalação do pacote pip do Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vXbpanX4jdHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f99d2b-7a5d-4661-eff1-7ff8fad3e79b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: earthengine-api in /usr/local/lib/python3.11/dist-packages (1.5.22)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.19.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.1 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.174.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (0.2.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (0.22.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.32.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.1->earthengine-api) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.1->earthengine-api) (4.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->earthengine-api) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->earthengine-api) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->earthengine-api) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1dev,>=0.9.2->earthengine-api) (3.2.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->earthengine-api) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->earthengine-api) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->earthengine-api) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (2025.6.15)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (1.26.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api) (0.6.1)\n",
            "time: 6.26 s (started: 2025-07-07 23:26:06 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install earthengine-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ia3WPhQF2-3t"
      },
      "outputs": [],
      "source": [
        "!earthengine authenticate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_c1csAt4BsK"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPz0Ktha4CsG"
      },
      "outputs": [],
      "source": [
        "# Import the Earth Engine API and initialize it.\n",
        "import ee\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFzZnNfJ4LuD"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "token = '4/1AX4XfWif2ASmQd28DqQmuR9blSSDRQqVHJ8d3Jri9TIPA4h832W7H1dWeKY'\n",
        "# Define the URL format used for Earth Engine generated map tiles.\n",
        "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
        "\n",
        "print('Folium version: ' + folium.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6AY3Qm72pyy"
      },
      "outputs": [],
      "source": [
        "pip install geemap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJR8K6wx2vtU"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import geemap\n",
        "import geemap.colormaps as cm\n",
        "import altair as alt\n",
        "import folium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdSGJyzBf0OS",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Mapdisplay: Display GEE objects using folium.\n",
        "def Mapdisplay(center, dicc, Tiles=\"OpensTreetMap\",zoom_start=10):\n",
        "    '''\n",
        "    :param center: Center of the map (Latitude and Longitude).\n",
        "    :param dicc: Earth Engine Geometries or Tiles dictionary\n",
        "    :param Tiles: Mapbox Bright,Mapbox Control Room,Stamen Terrain,Stamen Toner,stamenwatercolor,cartodbpositron.\n",
        "    :zoom_start: Initial zoom level for the map.\n",
        "    :return: A folium.Map object.\n",
        "    '''\n",
        "    mapViz = folium.Map(location=center,tiles=Tiles, zoom_start=zoom_start)\n",
        "    for k,v in dicc.items():\n",
        "      if ee.image.Image in [type(x) for x in v.values()]:\n",
        "        folium.TileLayer(\n",
        "            tiles = v[\"tile_fetcher\"].url_format,\n",
        "            attr  = 'Google Earth Engine',\n",
        "            overlay =True,\n",
        "            name  = k\n",
        "          ).add_to(mapViz)\n",
        "      else:\n",
        "        folium.GeoJson(\n",
        "        data = v,\n",
        "        name = k\n",
        "          ).add_to(mapViz)\n",
        "    mapViz.add_child(folium.LayerControl())\n",
        "    return mapViz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr868Rk9bRIA"
      },
      "source": [
        "## Data Extraction from GEE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5xDEJwJRIVV"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "ee.Initialize()\n",
        "\n",
        "def get_asset_list(parent):\n",
        "    parent_asset = ee.data.getAsset(parent)\n",
        "    parent_id = parent_asset['name']\n",
        "    parent_type = parent_asset['type']\n",
        "    asset_list = []\n",
        "    child_assets = ee.data.listAssets({'parent': parent_id})['assets']\n",
        "    for child_asset in child_assets:\n",
        "        child_id = child_asset['name']\n",
        "        child_type = child_asset['type']\n",
        "        if child_type in ['FOLDER','IMAGE_COLLECTION']:\n",
        "            # Recursively call the function to get child assets\n",
        "            asset_list.extend(get_asset_list(child_id))\n",
        "        else:\n",
        "            asset_list.append(child_id)\n",
        "    return asset_list\n",
        "\n",
        "all_assets = get_asset_list('projects/ee-alinephysics/assets/')\n",
        "\n",
        "print('Found {} assets'.format(len(all_assets)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWiTvmOBp0SD"
      },
      "outputs": [],
      "source": [
        "all_assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uijBV00pp0B8"
      },
      "outputs": [],
      "source": [
        "# import argparse\n",
        "# import ee\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('--old_collection', help='old collection')\n",
        "# parser.add_argument('--new_collection', help='new collection')\n",
        "# parser.add_argument('--delete', help='delete old collection',\n",
        "#     action=argparse.BooleanOptionalAction)\n",
        "\n",
        "# # args = parser.parse_args()\n",
        "\n",
        "# old_collection = old_collection\n",
        "# new_collection = new_collection\n",
        "\n",
        "# ee.Initialize()\n",
        "\n",
        "# # Check if new collection exists\n",
        "# try:\n",
        "#     ee.ImageCollection(new_collection).getInfo()\n",
        "# except:\n",
        "#     print('Collection {} does not exist'.format(new_collection))\n",
        "#     ee.data.createAsset({'type': ee.data.ASSET_TYPE_IMAGE_COLL}, new_collection)\n",
        "#     print('Created a new empty collection {}.'.format(new_collection))\n",
        "\n",
        "\n",
        "# assets = ee.data.listAssets({'parent': old_collection})['assets']\n",
        "\n",
        "\n",
        "# for asset in assets:\n",
        "#     old_name = asset['name']\n",
        "#     new_name = old_name.replace(old_collection, new_collection)\n",
        "#     print('Copying {} to {}'.format(old_name, new_name))\n",
        "#     ee.data.copyAsset(old_name, new_name, True)\n",
        "#     if args.delete:\n",
        "#         print('Deleting <{}>'.format(old_name))\n",
        "#         ee.data.deleteAsset(old_name)\n",
        "\n",
        "# if args.delete:\n",
        "#     print('Deleting Collection <{}>'.format(old_collection))\n",
        "#     ee.data.deleteAsset(old_collection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFxixoEXUKSN"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import os\n",
        "import geemap\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "\n",
        "def create_geodataframe_and_save_in_assets(df, path_name, asset_name):\n",
        "  # create a tmp gdf\n",
        "  gdf = gpd.GeoDataFrame(\n",
        "      df,\n",
        "      crs='EPSG:4326',\n",
        "      geometry = gpd.points_from_xy(\n",
        "          df['longitude'],\n",
        "          df['latitude']\n",
        "      )\n",
        "  )\n",
        "\n",
        "  # convert it into geo-json\n",
        "  json_df = json.loads(gdf.to_json())\n",
        "\n",
        "  # create a gee object with geemap\n",
        "  ee_object = geemap.geojson_to_ee(json_df)\n",
        "\n",
        "  # upload this object to earthengine\n",
        "  asset = os.path.join(path_name, asset_name)\n",
        "\n",
        "  #create and launch the task\n",
        "  task_config = {\n",
        "      'collection': ee_object,\n",
        "      'description':asset_name,\n",
        "      'assetId': asset\n",
        "  }\n",
        "  task = ee.batch.Export.table.toAsset(**task_config)\n",
        "  task.start()\n",
        "  return \"Success\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08i3HIBCi1Q9"
      },
      "source": [
        " ## MODIS: Downloading Data from GEE to Assets and Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install geopandas"
      ],
      "metadata": {
        "id": "dBIoZ3dJuCFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **MOD13A2 (Version 061):**  \n",
        "  16-day composite vegetation indices (12 spectral bands)  \n",
        "  Example date: February 18, 2000\n",
        "\n",
        "- **MCD15A3H (Version 061):**  \n",
        "  4-day composite Leaf Area Index (LAI) and Fraction of Photosynthetically Active Radiation (FPAR) data (6 bands)  \n",
        "  Example date: July 4, 2002"
      ],
      "metadata": {
        "id": "L5dkmm9qpI01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module for shapefile manipulation\n",
        "import geopandas as gpd\n",
        "\n",
        "def get_km67_data_var(name_collection, variable):\n",
        "  # Load the shapefile containing the polygon\n",
        "  shapefile_path = '/content/drive/MyDrive/bioma-amazonia/km67-7655cell-grid-era5-one-single0-25deg.shp'\n",
        "  gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "  # Example: Extract NDVI time series from the MODIS collection\n",
        "  collection = ee.ImageCollection(name_collection).select(variable)\n",
        "\n",
        "  # Get the polygon from the shapefile\n",
        "  polygon = ee.Geometry.Polygon(list(gdf['geometry'].iloc[0].exterior.coords))\n",
        "\n",
        "  # Filter images within the polygon and date range\n",
        "  filtered_collection = collection.filterBounds(polygon).filterDate('2002-01-01', '2012-01-01')\n",
        "\n",
        "  # Run the query and obtain the time series\n",
        "  time_series = filtered_collection.getRegion(polygon, scale=27830).getInfo()\n",
        "  return time_series\n",
        "\n",
        "def get_km67_data(name_collection):\n",
        "  # Load the shapefile containing the polygon\n",
        "  shapefile_path = '/content/drive/MyDrive/bioma-amazonia/km67-7655cell-grid-era5-one-single0-25deg.shp'\n",
        "  gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "  # Example: Extract time series from the image collection\n",
        "  collection = ee.ImageCollection(name_collection)\n",
        "\n",
        "  # Get the polygon from the shapefile\n",
        "  polygon = ee.Geometry.Polygon(list(gdf['geometry'].iloc[0].exterior.coords))\n",
        "\n",
        "  # Remaining code...\n",
        "\n",
        "  # Filter images within the polygon and date range\n",
        "  filtered_collection = collection.filterBounds(polygon).filterDate('2002-01-01', '2012-01-01')\n",
        "\n",
        "  # Run the query and obtain the time series\n",
        "  time_series = filtered_collection.getRegion(polygon, scale=27830).getInfo()\n",
        "  return time_series\n"
      ],
      "metadata": {
        "id": "U_2JaAFAjvH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_serie_MODIS_MCD15A3H =  get_km67_data(\"MODIS/061/MCD15A3H\")\n",
        "time_serie_MODIS_MOD13A2 =  get_km67_data(\"MODIS/061/MOD13A2\")"
      ],
      "metadata": {
        "id": "gPNcwYZQo1Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataframe_for_time_series_data(time_series,filename):\n",
        "  df = pd.DataFrame(time_series[1:], columns=time_series[0])\n",
        "\n",
        "  if '_' in df['id'][0]:\n",
        "    df['id'] = df['id'].str.replace('_','')\n",
        "\n",
        "  df['date'] = pd.to_datetime(df['id'], format='%Y%m%d')\n",
        "\n",
        "  df.to_csv(filename)\n",
        "  return df"
      ],
      "metadata": {
        "id": "syqLBYj431jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_MODIS_MCD15A3H = create_dataframe_for_time_series_data(time_serie_MODIS_MCD15A3H,'/content/drive/MyDrive/bioma-amazonia/cell_km67/time_series_MODIS_MCD15A3H.csv')\n",
        "df_MODIS_MOD13A2 = create_dataframe_for_time_series_data(time_serie_MODIS_MOD13A2,'/content/drive/MyDrive/bioma-amazonia/cell_km67/time_series_MODIS_MCD15A3H.csv')"
      ],
      "metadata": {
        "id": "kbEQ_yoJ1wm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = pd.read_csv('/content/drive/MyDrive/bioma-amazonia/cell_km67/time_series_MODIS_MCD15A3H.csv')\n",
        "t"
      ],
      "metadata": {
        "id": "EgU_5hXljZTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ☀️ CERES Radiation Data\n",
        "\n",
        "**Dataset links:**  \n",
        "- [CERES Data Portal](https://ceres.larc.nasa.gov/data/)  \n",
        "- [CERES SYN1deg Edition 4A Selection Tool](https://ceres-tool.larc.nasa.gov/ord-tool/jsp/SYN1degEd42Selection.jsp)  \n",
        "- [Data Quality Summary (CERES SYN1deg Ed4A)](https://ceres.larc.nasa.gov/documents/DQ_summaries/CERES_SYN1deg_Ed4A_DQS.pdf)\n",
        "\n",
        "**Description:**  \n",
        "The Clouds and the Earth's Radiant Energy System (CERES) dataset provides global measurements of radiative energy fluxes at the top of the atmosphere, surface, and within the atmosphere. It is widely used for climate studies and as an important predictor for ecosystem carbon flux modeling.\n",
        "\n",
        "This dataset offers variables such as:\n",
        "- Shortwave and longwave radiation fluxes  \n",
        "- Surface radiation budget components\n",
        "\n",
        "The data is available at a 1-degree spatial resolution and can be downloaded using the online selection tool or via FTP.\n",
        "\n"
      ],
      "metadata": {
        "id": "IS4oWPxLlnlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ☔ MERGE Precipitation Data\n",
        "\n",
        "**Data sources:**  \n",
        "- [MERGE GPM Daily Data FTP](https://ftp.cptec.inpe.br/modelos/tempo/MERGE/GPM/DAILY/)  \n",
        "- [MERGE GPM FTP Directory](https://ftp.cptec.inpe.br/modelos/tempo/MERGE/GPM/)  \n",
        "- [MERGE GPM Data Description (Rozante, 2024)](https://ftp.cptec.inpe.br/modelos/tempo/MERGE/GPM/Rozante.2024.pdf)\n",
        "\n",
        "**Description:**  \n",
        "The MERGE dataset combines satellite-based precipitation estimates with ground observations to provide daily rainfall data. It is produced by CPTEC/INPE and is widely used for hydrological and ecological studies in Brazil, including Amazon basin applications.\n",
        "\n",
        "This dataset is suitable as a predictor in NEE models, capturing rainfall variability at regional scales.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ifCSQsDZl694"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🌿 FluxCom NEE Estimates\n",
        "\n",
        "**Data source:**  \n",
        "[FluxCom FTP Server](ftp://ftp.bgc-jena.mpg.de)\n",
        "\n",
        "**Description:**  \n",
        "FluxCom provides machine learning-based estimates of Net Ecosystem Exchange (NEE) by combining eddy covariance flux tower data with remote sensing and meteorological predictors. The dataset covers multiple biomes globally and is widely used for benchmarking and model comparison studies in ecosystem carbon flux research.\n",
        "\n"
      ],
      "metadata": {
        "id": "yMnVw1W9m3TQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5LFVHqKVLW7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhtBoN8qVJhr"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = 'NEE.ANN.CRUNCEPv6.daily.1980.nc'"
      ],
      "metadata": {
        "id": "HGWEbv8xbkym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years = ['2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012']"
      ],
      "metadata": {
        "id": "Ncylmu39bw0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a[-7:-3]"
      ],
      "metadata": {
        "id": "Q7btxdDiboWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "/outgoing/FluxCom/CarbonFluxes/RS_METEO/ensemble/ERA5/monthly"
      ],
      "metadata": {
        "id": "imtepEWG256f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ftplib import FTP\n",
        "import os\n",
        "\n",
        "# FTP server details\n",
        "ftp_host = \"ftp.bgc-jena.mpg.de\"\n",
        "ftp_path = \"/outgoing/FluxCom/CarbonFluxes/RS_METEO/ensemble/ERA5/monthly\"\n",
        "\n",
        "# Path to save the files to Google Drive\n",
        "local_dir = \"/content/drive/My Drive/NEE_Files_daily_ERA5_RSMETEO_monthly\"\n",
        "\n",
        "# Create the directory on Google Drive if it doesn't exist\n",
        "os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "# Connect to the FTP server\n",
        "ftp = FTP(ftp_host)\n",
        "ftp.login()  # Anonymous login\n",
        "\n",
        "# Navigate to the specific directory\n",
        "ftp.cwd(ftp_path)\n",
        "\n",
        "# List files in the directory\n",
        "files = ftp.nlst()\n",
        "\n",
        "# Filter files that start with \"NEE\"\n",
        "nee_files = [\n",
        "    file for file in files\n",
        "    if file.startswith(\"NEE\")\n",
        "]\n",
        "\n",
        "# Download the files\n",
        "for file in nee_files:\n",
        "    local_file_path = os.path.join(local_dir, file)\n",
        "    with open(local_file_path, \"wb\") as local_file:\n",
        "        ftp.retrbinary(f\"RETR {file}\", local_file.write)\n",
        "    print(f\"File {file} successfully downloaded to {local_file_path}\")\n",
        "\n",
        "# Close the FTP connection\n",
        "ftp.quit()\n"
      ],
      "metadata": {
        "id": "wIZlRI1i27H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ftplib import FTP\n",
        "import os\n",
        "\n",
        "# FTP server details\n",
        "ftp_host = \"ftp.bgc-jena.mpg.de\"\n",
        "ftp_path = \"/outgoing/FluxCom/CarbonFluxes_v1_2017/RS+METEO/CRUNCEPv6/raw/daily\"\n",
        "\n",
        "# Path to save the files in Google Drive\n",
        "local_dir = \"/content/drive/My Drive/NEE_Files_daily_Cruncepv6_RSMETEO\"\n",
        "\n",
        "# Create the directory in Google Drive if it doesn't exist\n",
        "os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "# Connect to the FTP server\n",
        "ftp = FTP(ftp_host)\n",
        "ftp.login()  # Anonymous login\n",
        "\n",
        "# Navigate to the target directory\n",
        "ftp.cwd(ftp_path)\n",
        "\n",
        "# List files in the directory\n",
        "files = ftp.nlst()\n",
        "\n",
        "# Filter files that start with \"NEE\"\n",
        "nee_files = [\n",
        "    file for file in files\n",
        "    if file.startswith(\"NEE\")\n",
        "]\n",
        "\n",
        "# Download the files\n",
        "for file in nee_files:\n",
        "    local_file_path = os.path.join(local_dir, file)\n",
        "    with open(local_file_path, \"wb\") as local_file:\n",
        "        ftp.retrbinary(f\"RETR {file}\", local_file.write)\n",
        "    print(f\"File {file} successfully downloaded to {local_file_path}\")\n",
        "\n",
        "# Close the FTP connection\n",
        "ftp.quit()\n"
      ],
      "metadata": {
        "id": "PE5x7vJ7a86u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ftplib import FTP\n",
        "import os\n",
        "\n",
        "# FTP server details\n",
        "ftp_host = \"ftp.bgc-jena.mpg.de\"\n",
        "ftp_path = \"/outgoing/FluxCom/CarbonFluxes_v1_2017/RS+METEO/WFDEI/raw/daily\"\n",
        "\n",
        "# Path to save the files in Google Drive\n",
        "local_dir = \"/content/drive/My Drive/NEE_Files_daily_WFDEI_RSMETEO\"\n",
        "\n",
        "# Create the directory in Google Drive if it doesn't exist\n",
        "os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "# Connect to the FTP server\n",
        "ftp = FTP(ftp_host)\n",
        "ftp.login()  # Anonymous login\n",
        "\n",
        "# Navigate to the target directory\n",
        "ftp.cwd(ftp_path)\n",
        "\n",
        "# List files in the directory\n",
        "files = ftp.nlst()\n",
        "\n",
        "# Filter files that start with \"NEE\"\n",
        "nee_files = [\n",
        "    file for file in files\n",
        "    if file.startswith(\"NEE\")\n",
        "]\n",
        "\n",
        "# Download the files\n",
        "for file in nee_files:\n",
        "    local_file_path = os.path.join(local_dir, file)\n",
        "    with open(local_file_path, \"wb\") as local_file:\n",
        "        ftp.retrbinary(f\"RETR {file}\", local_file.write)\n",
        "    print(f\"File {file} successfully downloaded to {local_file_path}\")\n",
        "\n",
        "# Close the FTP connection\n",
        "ftp.quit()\n"
      ],
      "metadata": {
        "id": "2kkAcuizbQb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPP /outgoing/FluxCom/CarbonFluxes_v1_2017/RS/ensemble/720_360/8daily"
      ],
      "metadata": {
        "id": "mLlEmtbbdnss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Updated Daily NEE (2023)\n",
        "\n",
        "/outgoing/FluxCom/CarbonFluxes/RS_METEO/member/CRUNCEP_v8/daily"
      ],
      "metadata": {
        "id": "0Lb0HwK8enq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ftplib import FTP\n",
        "import os\n",
        "\n",
        "# FTP server details\n",
        "ftp_host = \"ftp.bgc-jena.mpg.de\"\n",
        "ftp_path = \"/outgoing/FluxCom/CarbonFluxes/RS_METEO/member/CRUNCEP_v8/daily\"\n",
        "\n",
        "# Path to save the files in Google Drive\n",
        "local_dir = \"/content/drive/My Drive/NEE_Files_daily_Cruncep_v8_update2023\"\n",
        "\n",
        "# Create the directory in Google Drive if it doesn't exist\n",
        "os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "# Connect to the FTP server\n",
        "ftp = FTP(ftp_host)\n",
        "ftp.login()  # Anonymous login\n",
        "\n",
        "# Navigate to the target directory\n",
        "ftp.cwd(ftp_path)\n",
        "\n",
        "# List files in the directory\n",
        "files = ftp.nlst()\n",
        "\n",
        "# Filter files that start with \"NEE\"\n",
        "nee_files = [\n",
        "    file for file in files\n",
        "    if file.startswith(\"NEE\")\n",
        "]\n",
        "\n",
        "# Download the files\n",
        "for file in nee_files:\n",
        "    local_file_path = os.path.join(local_dir, file)\n",
        "    with open(local_file_path, \"wb\") as local_file:\n",
        "        ftp.retrbinary(f\"RETR {file}\", local_file.write)\n",
        "    print(f\"File {file} successfully downloaded to {local_file_path}\")\n",
        "\n",
        "# Close the FTP connection\n",
        "ftp.quit()\n"
      ],
      "metadata": {
        "id": "R_VFxvnYetVV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}